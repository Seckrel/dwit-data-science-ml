{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db769c46-0b0c-4ad6-8dbb-efe61967345c",
   "metadata": {},
   "source": [
    "# Understanding Natural Language Processing (NLP)\n",
    "Natural Language Processing (NLP) is a branch of artificial intelligence (AI) focused on enabling computers to understand, interpret, and respond to human language in a way that is both meaningful and useful. NLP bridges the gap between human communication and machine understanding, leveraging computational methods to process and analyze large amounts of natural language data. It combines principles of linguistics, computer science, and machine learning to tackle the complexities of human language."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab37da89-b7bd-424b-b8f2-c3a42e67acdd",
   "metadata": {},
   "source": [
    "## Key Concepts\n",
    "1. Tokenization  \n",
    "Tokenization is the process of breaking down a text into smaller units called tokens, which can be words, phrases, or characters. For example, the sentence \"NLP is fascinating!\" can be tokenized into [\"NLP\", \"is\", \"fascinating\", \"!\"].\n",
    "\n",
    "    - Word-level tokenization focuses on splitting text into words.\n",
    "    - Subword tokenization is used in tasks like machine translation where partial words may carry meaning.\n",
    "    - Sentence tokenization splits text into sentences.\n",
    "\n",
    "2. Part-of-Speech (POS) Tagging  \n",
    "This involves labeling words in a sentence with their grammatical roles, such as noun, verb, adjective, etc. For example:\n",
    "\n",
    "    - \"The dog barks\" → \"The (determiner) dog (noun) barks (verb)\".\n",
    "\n",
    "3. Named Entity Recognition (NER)  \n",
    "NER identifies and classifies entities within text, such as names of people, organizations, locations, dates, and more.\n",
    "\n",
    "    - Example: \"Barack Obama was born in Hawaii\" → Barack Obama (Person), Hawaii (Location).\n",
    "\n",
    "4. Sentiment Analysis  \n",
    "Sentiment analysis determines the emotional tone or opinion expressed in a piece of text. It categorizes text as positive, negative, or neutral, often used in product reviews or social media analysis.\n",
    "\n",
    "    - Example: \"I love this product!\" → Positive sentiment.\n",
    "\n",
    "5. Stemming and Lemmatization  \n",
    "These techniques reduce words to their root forms to simplify text processing:\n",
    "\n",
    "    - Stemming chops off inflections (e.g., \"running\" → \"run\").\n",
    "    - Lemmatization considers the context to return the base form (e.g., \"better\" → \"good\").\n",
    "\n",
    "6. Syntax and Parsing  \n",
    "Parsing analyzes the grammatical structure of a sentence to understand its syntax. Dependency parsing identifies relationships between words in a sentence, aiding in understanding complex sentences.\n",
    "\n",
    "7. Text Classification  \n",
    "Text classification assigns predefined categories to text, such as spam detection in emails or categorizing news articles into topics.\n",
    "\n",
    "8. Language Modeling  \n",
    "Language models predict the probability of word sequences, enabling applications like autocomplete, speech recognition, and machine translation. Models like GPT (Generative Pre-trained Transformer) represent state-of-the-art approaches in this area."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf7cb68-7255-4125-becd-90dbd71ea4ad",
   "metadata": {},
   "source": [
    "**Installing NLTK**\n",
    "`pip install nltk`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3b1d69d0-1a6e-49c8-ad3b-9be915e4ae7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import pos_tag, ne_chunk\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from nltk.tree import Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b91de3b9-df82-4ac2-8c8d-8fdd28e5487b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /Users/aayamojha/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]     /Users/aayamojha/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package maxent_ne_chunker_tab to\n",
      "[nltk_data]     /Users/aayamojha/nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker_tab is already up-to-date!\n",
      "[nltk_data] Downloading package words to /Users/aayamojha/nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/aayamojha/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/aayamojha/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download required NLTK data files\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('averaged_perceptron_tagger_eng')\n",
    "nltk.download('maxent_ne_chunker_tab')\n",
    "nltk.download('words')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96cc1a9a-fd27-493a-b7b5-aec31df4a15d",
   "metadata": {},
   "source": [
    "| **Download**                 | **Purpose**                                                             | **Used By**                        |\n",
    "|------------------------------|-------------------------------------------------------------------------|-----------------------------------|\n",
    "| `punkt_tab`                     | Sentence and word tokenization rules.                                   | `sent_tokenize`, `word_tokenize`. |\n",
    "| `averaged_perceptron_tagger_eng`| POS tagging model.                                                     | `nltk.pos_tag`.                   |\n",
    "| `maxent_ne_chunker_tab`         | Named Entity Recognition (NER).                                         | `nltk.ne_chunk`.                  |\n",
    "| `words`                     | English vocabulary dataset for validation in NER and other tasks.       | `nltk.ne_chunk` (indirectly).     |\n",
    "| `wordnet`                   | Lexical database for lemmatization and advanced semantic analysis.      | `WordNetLemmatizer`.              |\n",
    "| `stopwords`                 | List of stop words for filtering.                                       | `nltk.corpus.stopwords`.          |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "92b4993a-1151-42ad-a58d-81fb0345f9a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example text\n",
    "text = \"\"\"Natural Language Processing (NLP) is a fascinating field of AI. \n",
    "          Researchers use it to develop tools like chatbots, translators, and summarizers.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9ce76461-1f5c-4675-9900-9eee6ab3abc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenization:\n",
      "Sentences: ['Natural Language Processing (NLP) is a fascinating field of AI.', 'Researchers use it to develop tools like chatbots, translators, and summarizers.']\n"
     ]
    }
   ],
   "source": [
    "print(\"Tokenization:\")\n",
    "sentences = sent_tokenize(text)  # Sentence Tokenization\n",
    "print(\"Sentences:\", sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0b72e957-f980-4aa8-b073-146cf51fe60f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words: ['Natural', 'Language', 'Processing', '(', 'NLP', ')', 'is', 'a', 'fascinating', 'field', 'of', 'AI', '.', 'Researchers', 'use', 'it', 'to', 'develop', 'tools', 'like', 'chatbots', ',', 'translators', ',', 'and', 'summarizers', '.']\n"
     ]
    }
   ],
   "source": [
    "words = word_tokenize(text)  # Word Tokenization\n",
    "print(\"Words:\", words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7516f7bf-ec91-412f-bf2c-729375661a53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Part-of-Speech (POS) Tagging:\n",
      "POS Tags: [('Natural', 'JJ'), ('Language', 'NNP'), ('Processing', 'NNP'), ('(', '('), ('NLP', 'NNP'), (')', ')'), ('is', 'VBZ'), ('a', 'DT'), ('fascinating', 'JJ'), ('field', 'NN'), ('of', 'IN'), ('AI', 'NNP'), ('.', '.'), ('Researchers', 'NNP'), ('use', 'VBP'), ('it', 'PRP'), ('to', 'TO'), ('develop', 'VB'), ('tools', 'NNS'), ('like', 'IN'), ('chatbots', 'NNS'), (',', ','), ('translators', 'NNS'), (',', ','), ('and', 'CC'), ('summarizers', 'NNS'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nPart-of-Speech (POS) Tagging:\")\n",
    "pos_tags = pos_tag(words)\n",
    "print(\"POS Tags:\", pos_tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "876a0b8c-e9bb-4c7c-b959-fd52fcb0f208",
   "metadata": {},
   "source": [
    "| Tag   | Meaning                                   |\n",
    "|-----|:-------------------------------------------:|\n",
    "| CC    | Coordinating conjunction                 |\n",
    "| CD    | Cardinal number                          |\n",
    "| DT    | Determiner                               |\n",
    "| EX    | Existential                              |\n",
    "| FW    | Foreign word                             |\n",
    "| IN    | Preposition or conjunction               |\n",
    "| JJ    | Adjective                                |\n",
    "| JJR   | Adjective, comparative                   |\n",
    "| JJS   | Adjective, superlative                   |\n",
    "| LS    | List item marker                         |\n",
    "| MD    | Modal                                    |\n",
    "| NN    | Noun, singular                           |\n",
    "| NNS   | Noun, plural                             |\n",
    "| NNP   | Proper noun, singular                    |\n",
    "| NNPS  | Proper noun, plural                      |\n",
    "| PDT   | Predeterminer                            |\n",
    "| POS   | Possessive ending                        |\n",
    "| PRP   | Personal pronoun                         |\n",
    "| PRP\\$  | Possessive pronoun                       |\n",
    "| RB    | Adverb                                   |\n",
    "| RBR   | Adverb, comparative                      |\n",
    "| RBS   | Adverb, superlative                      |\n",
    "| RP    | Particle                                 |\n",
    "| SYM   | Symbol                                   |\n",
    "| TO    | To                                       |\n",
    "| UH    | Interjection                             |\n",
    "| VB    | Verb, base form                          |\n",
    "| VBD   | Verb, past tense                         |\n",
    "| VBG   | Verb, gerund or participle               |\n",
    "| VBN   | Verb, past participle                    |\n",
    "| VBP   | Verb, non-3rd person singular present    |\n",
    "| VBZ   | Verb, 3rd person singular present        |\n",
    "| WDT   | Wh-determiner                            |\n",
    "| WP    | Wh-pronoun                               |\n",
    "| WP$   | Possessive wh-pronoun                    |\n",
    "| WRB   | Wh-adverb                                |\n",
    "| .     | Punctuation mark                         |\n",
    "| ,     | Punctuation mark                         |\n",
    "| :     | Punctuation mark                         |\n",
    "| (     | Left parenthesis                         |\n",
    "| )     | Right parenthesis                        |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "bab7d87d-4a08-45f2-b4c6-1976bc21d65e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stemming:\n",
      "Stems: ['natur', 'languag', 'process', '(', 'nlp', ')', 'is', 'a', 'fascin', 'field', 'of', 'ai', '.', 'research', 'use', 'it', 'to', 'develop', 'tool', 'like', 'chatbot', ',', 'translat', ',', 'and', 'summar', '.']\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nStemming:\")\n",
    "stemmer = PorterStemmer()\n",
    "stems = [stemmer.stem(word) for word in words]\n",
    "print(\"Stems:\", stems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8407fd99-f1de-4f08-9bf8-c75ea1b5e4dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Lemmatization:\n",
      "Lemmas: ['Natural', 'Language', 'Processing', '(', 'NLP', ')', 'is', 'a', 'fascinating', 'field', 'of', 'AI', '.', 'Researchers', 'use', 'it', 'to', 'develop', 'tool', 'like', 'chatbots', ',', 'translator', ',', 'and', 'summarizers', '.']\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nLemmatization:\")\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "lemmas = [lemmatizer.lemmatize(word) for word in words]\n",
    "print(\"Lemmas:\", lemmas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7fc904f-68ec-452f-a33a-6085d5fff229",
   "metadata": {},
   "source": [
    "# Difference Between Stemming and Lemmatization\n",
    "Both stemming and lemmatization are techniques used in natural language processing (NLP) to reduce words to their base or root forms. However, they differ in their approaches, accuracy, and output.  \n",
    "\n",
    "## Stemming\n",
    "- Definition: Stemming is the process of cutting off prefixes and suffixes from a word to get its root form, often without considering the meaning of the word. It can sometimes result in non-existent words.\n",
    "- Approach: Stemming uses heuristic rules to remove affixes (prefixes and suffixes) from a word. It is generally faster but less accurate than lemmatization.\n",
    "- Output: Stemming may produce words that are not real words in the dictionary.\n",
    "\n",
    "**Example of Stemming:**\n",
    "- Word: \"running\"\n",
    "- Stemmed Form: \"run\" (correct)\n",
    "- Word: \"better\"\n",
    "- Stemmed Form: \"better\" (incorrect because it's not reduced to the base form)\n",
    "\n",
    "## Lemmatization\n",
    "- Definition: Lemmatization is the process of reducing a word to its base or dictionary form (lemma), which is a valid word. Unlike stemming, lemmatization considers the context and the part of speech (POS) of the word.\n",
    "- Approach: Lemmatization uses a vocabulary and morphological analysis to convert a word into its proper base form. It is more computationally intensive but produces accurate results.\n",
    "- Output: The result of lemmatization is always a valid word in the dictionary.\n",
    "\n",
    "**Example of Lemmatization:**\n",
    "- Word: \"running\"\n",
    "- Lemmatized Form: \"run\" (correct)\n",
    "- Word: \"better\"\n",
    "- Lemmatized Form: \"good\" (correct as the lemma of \"better\" is \"good\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4b5d3a8-a2ba-4039-873d-e69b026e925d",
   "metadata": {},
   "source": [
    "# What are Stopwords?\n",
    "Stopwords are common words that are filtered out in text processing tasks, especially in Natural Language Processing (NLP). These words typically don't add significant meaning or value to the analysis of the content. They are usually very frequent words in a language and often consist of functional words like pronouns, prepositions, articles, conjunctions, and auxiliary verbs.  \n",
    "\n",
    "Stopwords are removed from the text to reduce the dataset's size and to focus the analysis on the more meaningful words."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fcfb1ba-49f3-4bb6-bb30-00abb03a7f4c",
   "metadata": {},
   "source": [
    "## Where Do Stopwords Come From?\n",
    "Stopwords come from the structure of natural language and the need to process text in a more meaningful way. In a sentence, words like \"and,\" \"the,\" \"is,\" \"of,\" etc., are necessary for the sentence to make grammatical sense but don't contribute significant semantic value. Removing these words helps focus on the key content words that are more relevant for many NLP tasks like text classification, sentiment analysis, and information retrieval.  \n",
    "\n",
    "**For example:**  \n",
    "\n",
    "- Original Sentence: \"The quick brown fox jumps over the lazy dog.\"\n",
    "- Stopwords Removed: \"quick brown fox jumps lazy dog.\"\n",
    "- By removing stopwords, the focus shifts to the main content of the sentence.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "106a8b5f-262c-43e6-b0ff-738b5749b6f4",
   "metadata": {},
   "source": [
    "## What Words Are Chosen as Stopwords?\n",
    "The specific words chosen as stopwords depend on the language and the task. However, stopwords are generally function words that do not carry much meaning by themselves. These typically include:  \n",
    "\n",
    "**Common Stopwords in English:**\n",
    "- Articles: \"a\", \"an\", \"the\"\n",
    "- Prepositions: \"in\", \"on\", \"at\", \"by\", \"with\"\n",
    "- Pronouns: \"I\", \"you\", \"he\", \"she\", \"it\", \"we\", \"they\"\n",
    "- Conjunctions: \"and\", \"but\", \"or\", \"because\", \"if\"\n",
    "- Auxiliary Verbs: \"is\", \"are\", \"was\", \"were\", \"have\", \"has\", \"do\", \"does\"\n",
    "- Determiners: \"this\", \"that\", \"these\", \"those\"\n",
    "- Other Common Words: \"to\", \"for\", \"of\", \"from\", \"as\", \"so\", \"up\", \"down\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b6a40a07-50b4-43e0-bb99-f6204985dc4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Natural Language Processing (NLP) is a fascinating field of AI. \\n          Researchers use it to develop tools like chatbots, translators, and summarizers.'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1ca0bbed-59a5-48d9-97e1-9befaf47ab3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Natural', 'Language', 'Processing', '(', 'NLP', ')', 'fascinating', 'field', 'AI', '.', 'Researchers', 'use', 'develop', 'tools', 'like', 'chatbots', ',', 'translators', ',', 'summarizers', '.']\n"
     ]
    }
   ],
   "source": [
    "words = word_tokenize(text)\n",
    "\n",
    "# Load stopwords from NLTK\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Filter out stopwords\n",
    "filtered_words = [word for word in words if word.lower() not in stop_words]\n",
    "\n",
    "print(filtered_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "dfd35ba2-bd3f-4fe1-abfb-e27e9048491e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a',\n",
       " 'about',\n",
       " 'above',\n",
       " 'after',\n",
       " 'again',\n",
       " 'against',\n",
       " 'ain',\n",
       " 'all',\n",
       " 'am',\n",
       " 'an',\n",
       " 'and',\n",
       " 'any',\n",
       " 'are',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'as',\n",
       " 'at',\n",
       " 'be',\n",
       " 'because',\n",
       " 'been',\n",
       " 'before',\n",
       " 'being',\n",
       " 'below',\n",
       " 'between',\n",
       " 'both',\n",
       " 'but',\n",
       " 'by',\n",
       " 'can',\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'd',\n",
       " 'did',\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'do',\n",
       " 'does',\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'doing',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'down',\n",
       " 'during',\n",
       " 'each',\n",
       " 'few',\n",
       " 'for',\n",
       " 'from',\n",
       " 'further',\n",
       " 'had',\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'has',\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'have',\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'having',\n",
       " 'he',\n",
       " 'her',\n",
       " 'here',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'him',\n",
       " 'himself',\n",
       " 'his',\n",
       " 'how',\n",
       " 'i',\n",
       " 'if',\n",
       " 'in',\n",
       " 'into',\n",
       " 'is',\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'just',\n",
       " 'll',\n",
       " 'm',\n",
       " 'ma',\n",
       " 'me',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'more',\n",
       " 'most',\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'my',\n",
       " 'myself',\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'now',\n",
       " 'o',\n",
       " 'of',\n",
       " 'off',\n",
       " 'on',\n",
       " 'once',\n",
       " 'only',\n",
       " 'or',\n",
       " 'other',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'out',\n",
       " 'over',\n",
       " 'own',\n",
       " 're',\n",
       " 's',\n",
       " 'same',\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'so',\n",
       " 'some',\n",
       " 'such',\n",
       " 't',\n",
       " 'than',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'the',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'them',\n",
       " 'themselves',\n",
       " 'then',\n",
       " 'there',\n",
       " 'these',\n",
       " 'they',\n",
       " 'this',\n",
       " 'those',\n",
       " 'through',\n",
       " 'to',\n",
       " 'too',\n",
       " 'under',\n",
       " 'until',\n",
       " 'up',\n",
       " 've',\n",
       " 'very',\n",
       " 'was',\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'we',\n",
       " 'were',\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'what',\n",
       " 'when',\n",
       " 'where',\n",
       " 'which',\n",
       " 'while',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'why',\n",
       " 'will',\n",
       " 'with',\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\",\n",
       " 'y',\n",
       " 'you',\n",
       " \"you'd\",\n",
       " \"you'll\",\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves'}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b830c099-1bb0-4c76-9fae-7dbf836c9ed9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
