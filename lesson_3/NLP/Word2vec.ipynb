{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54c54eb4-5f1d-45ad-b580-c185d4ebd686",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a33066dd-716f-4f24-904f-282ad7795da3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /Users/aayamojha/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1dd41e2f-1bbb-462a-a289-e83e43843d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\n",
    "    \"I love programming\",\n",
    "    \"I love coding\",\n",
    "    \"Programming is fun\",\n",
    "    \"Python is a great programming language\",\n",
    "    \"I am learning Word2Vec\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f36f3f9-acd3-4168-971f-aba34367bb63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizing the sentences (tokenize into words)\n",
    "tokenized_sentences = [word_tokenize(sentence.lower()) for sentence in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e90222ff-6889-4401-ab49-398cf06e4303",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec(sentences=tokenized_sentences, vector_size=100, window=5, min_count=1, sg=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6e482102-06ae-4e36-bfe8-4c419c46bcdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vector = model.wv['programming']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "01fbf4fd-332e-46d1-a1e4-f621f7889ef1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-5.3622725e-04,  2.3643136e-04,  5.1033497e-03,  9.0092728e-03,\n",
       "       -9.3029495e-03, -7.1168090e-03,  6.4588725e-03,  8.9729885e-03,\n",
       "       -5.0154282e-03, -3.7633716e-03,  7.3805046e-03, -1.5334714e-03,\n",
       "       -4.5366134e-03,  6.5540518e-03, -4.8601604e-03, -1.8160177e-03,\n",
       "        2.8765798e-03,  9.9187379e-04, -8.2852151e-03, -9.4488179e-03,\n",
       "        7.3117660e-03,  5.0702621e-03,  6.7576934e-03,  7.6286553e-04,\n",
       "        6.3508903e-03, -3.4053659e-03, -9.4640139e-04,  5.7685734e-03,\n",
       "       -7.5216377e-03, -3.9361035e-03, -7.5115822e-03, -9.3004224e-04,\n",
       "        9.5381187e-03, -7.3191668e-03, -2.3337686e-03, -1.9377411e-03,\n",
       "        8.0774371e-03, -5.9308959e-03,  4.5162440e-05, -4.7537340e-03,\n",
       "       -9.6035507e-03,  5.0072931e-03, -8.7595852e-03, -4.3918253e-03,\n",
       "       -3.5099984e-05, -2.9618145e-04, -7.6612402e-03,  9.6147433e-03,\n",
       "        4.9820580e-03,  9.2331432e-03, -8.1579173e-03,  4.4957981e-03,\n",
       "       -4.1370760e-03,  8.2453608e-04,  8.4986202e-03, -4.4621765e-03,\n",
       "        4.5175003e-03, -6.7869602e-03, -3.5484887e-03,  9.3985079e-03,\n",
       "       -1.5776526e-03,  3.2137157e-04, -4.1406299e-03, -7.6826881e-03,\n",
       "       -1.5080082e-03,  2.4697948e-03, -8.8802696e-04,  5.5336617e-03,\n",
       "       -2.7429771e-03,  2.2600652e-03,  5.4557943e-03,  8.3459532e-03,\n",
       "       -1.4537406e-03, -9.2081428e-03,  4.3705525e-03,  5.7178497e-04,\n",
       "        7.4419081e-03, -8.1328274e-04, -2.6384138e-03, -8.7530091e-03,\n",
       "       -8.5655687e-04,  2.8265631e-03,  5.4014288e-03,  7.0526563e-03,\n",
       "       -5.7031214e-03,  1.8588197e-03,  6.0888636e-03, -4.7980510e-03,\n",
       "       -3.1072604e-03,  6.7976294e-03,  1.6314756e-03,  1.8991709e-04,\n",
       "        3.4736372e-03,  2.1777749e-04,  9.6188262e-03,  5.0606038e-03,\n",
       "       -8.9173904e-03, -7.0415605e-03,  9.0145587e-04,  6.3925339e-03],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8557753d-7675-48d6-955f-5310638d6bfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99023621-6db4-45c0-adc5-024dfeee0b19",
   "metadata": {},
   "source": [
    "# similar_words = model.wv.most_similar('programming', topn=3)\n",
    "similar_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6a4cfe5b-4fac-4fe4-917e-de2c125bc457",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"Key 'king' not present in vocabulary\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m analogy_result \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmost_similar\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpositive\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mking\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mwoman\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnegative\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mman\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtopn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m analogy_result\n",
      "File \u001b[0;32m~/DWIT-TC/data_science_ml/lesson_3/venv/lib/python3.12/site-packages/gensim/models/keyedvectors.py:841\u001b[0m, in \u001b[0;36mKeyedVectors.most_similar\u001b[0;34m(self, positive, negative, topn, clip_start, clip_end, restrict_vocab, indexer)\u001b[0m\n\u001b[1;32m    838\u001b[0m         weight[idx] \u001b[38;5;241m=\u001b[39m item[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    840\u001b[0m \u001b[38;5;66;03m# compute the weighted average of all keys\u001b[39;00m\n\u001b[0;32m--> 841\u001b[0m mean \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_mean_vector\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpre_normalize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpost_normalize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_missing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    842\u001b[0m all_keys \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    843\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_index(key) \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m keys \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, _KEY_TYPES) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhas_index_for(key)\n\u001b[1;32m    844\u001b[0m ]\n\u001b[1;32m    846\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m indexer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(topn, \u001b[38;5;28mint\u001b[39m):\n",
      "File \u001b[0;32m~/DWIT-TC/data_science_ml/lesson_3/venv/lib/python3.12/site-packages/gensim/models/keyedvectors.py:518\u001b[0m, in \u001b[0;36mKeyedVectors.get_mean_vector\u001b[0;34m(self, keys, weights, pre_normalize, post_normalize, ignore_missing)\u001b[0m\n\u001b[1;32m    516\u001b[0m         total_weight \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mabs\u001b[39m(weights[idx])\n\u001b[1;32m    517\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ignore_missing:\n\u001b[0;32m--> 518\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mKey \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m not present in vocabulary\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    520\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m total_weight \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    521\u001b[0m     mean \u001b[38;5;241m=\u001b[39m mean \u001b[38;5;241m/\u001b[39m total_weight\n",
      "\u001b[0;31mKeyError\u001b[0m: \"Key 'king' not present in vocabulary\""
     ]
    }
   ],
   "source": [
    "analogy_result = model.wv.most_similar(positive=['king', 'woman'], negative=['man'], topn=1)\n",
    "analogy_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "566330e3-38a8-457f-9a6b-06a294fbeb6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('python', 0.17057989537715912), ('is', 0.15744781494140625)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analogy_result = model.wv.most_similar(positive=['fun', 'coding'], topn=2)\n",
    "analogy_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b33bb80e-a426-40c9-ac77-5528690b75d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"word2vec.model\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
